#!/usr/bin/env python3

# This file is part of Cockpit.
#
# Copyright (C) 2020 Red Hat, Inc.
#
# Cockpit is free software; you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation; either version 2.1 of the License, or
# (at your option) any later version.
#
# Cockpit is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with Cockpit; If not, see <http://www.gnu.org/licenses/>.

import re
import sys
import time
import sqlite3
import argparse
import logging
import json
from collections import Counter

# Seconds in a day
DAY = 86400


def main():
    parser = argparse.ArgumentParser(description='Generate statistics about failed tests')
    parser.add_argument("--db", default="cockpit-failures.db", help="Database name")
    parser.add_argument("--days", default=14, type=int,
                        help="Number of days to take statistics from. Default is %(default)s.")
    parser.add_argument("--verbose", action="store_true", help="Enable verbose logging")
    opts = parser.parse_args()

    if opts.verbose:
        logging.basicConfig(level=logging.DEBUG)

    db_conn = sqlite3.connect(opts.db)
    cursor = db_conn.cursor()

    all_tables = []
    since = time.time() - opts.days * DAY

    # Get all failures sorted by number of occurrences
    top10 = []
    rows = cursor.execute("""\
            SELECT testname, COUNT(run)
            FROM Failures
            JOIN TestRuns ON Failures.run = TestRuns.id
            WHERE TestRuns.time > ?
            GROUP BY testname
            ORDER BY COUNT(run) DESC
            LIMIT 10;""", (since, )).fetchall()
    for row in rows:
        urls = cursor.execute("""\
                SELECT DISTINCT TestRuns.url
                FROM TestRuns JOIN Failures ON TestRuns.id = Failures.run
                WHERE testname = ?
                ORDER BY run DESC
                LIMIT 2;""", (row[0], )).fetchall()
        links = [urls[0][0]] if len(urls) > 0 else []
        if len(urls) > 1:
            links.append(urls[1][0])
        top10.append([row[0], row[1], links])

    all_tables.append({"name": "Top failures", "columns": ["Test name", "Count", "Logs"], "data": top10})

    # Get failures by OS
    contexts = cursor.execute("SELECT DISTINCT context FROM TestRuns WHERE TestRuns.time > ? ;", (since, )).fetchall()
    for context in contexts:
        # For each OS get top 10 failures
        context = context[0]
        top10 = []
        rows = cursor.execute("""\
                SELECT testname, COUNT(run)
                FROM Failures
                JOIN TestRuns ON Failures.run = TestRuns.id
                WHERE TestRuns.context = ? AND TestRuns.time > ?
                GROUP BY testname
                ORDER BY COUNT(run) DESC
                LIMIT 10;""", (context, since,)).fetchall()
        for row in rows:
            urls = cursor.execute("""\
                    SELECT DISTINCT TestRuns.url
                    FROM TestRuns JOIN Failures ON TestRuns.id = Failures.run
                    WHERE testname = ? and context = ?
                    ORDER BY run DESC
                    LIMIT 2;""", (row[0], context,)).fetchall()
            links = [urls[0][0]] if len(urls) > 0 else []
            if len(urls) > 1:
                links.append(urls[1][0])
            top10.append([row[0], row[1], links])

        all_tables.append({"name": "Top failures for " + context,
                           "columns": ["Test name", "Count", "Logs"],
                           "data": top10})

    # Sort tables
    all_tables = sorted(all_tables, key=lambda x: x["data"][0][1], reverse=True)

    # Select unexpected messages
    messages = cursor.execute("""\
            SELECT retry_reason, TestRuns.url
            FROM Failures
            JOIN TestRuns ON Failures.run = TestRuns.id
            WHERE TestRuns.time > ? AND
                retry_reason IS NOT null AND
                retry_reason IS NOT 'be robust against unstable tests' AND
                retry_reason IS NOT 'due to failure of test harness or framework';""", (since,)).fetchall()

    messages = [m for m in messages if m[0] is not None]
    # Replace any numbers > 100 with 0 (usually time stamps or PIDs)
    messages = [(re.sub(r'\d\d[\d\.]+', '0', m[0]), m[1]) for m in messages]

    # Replace any partial paths like dracut.xf8hG with dracut.xxx
    messages = [(re.sub(r'(/[^/ \t]{3,}\.)[^/ \t]+', r'\1xxx', m[0]), m[1]) for m in messages]

    data = []
    for c in Counter([m[0] for m in messages]).most_common():
        if (c[1] > 1):  # Don't show message that happened just once
            logs = [m[1] for m in messages if m[0] == c[0]][:2]
            data.append([c[0], c[1], logs])

    if data:
        all_tables.insert(0, {"name": "Unexpected messages",
                              "columns": ["Message", "Count", "Logs"],
                              "data": data})

    print("const tables = {0};".format(json.dumps(all_tables)))

    db_conn.close()


if __name__ == '__main__':
    sys.exit(main())
