#!/usr/bin/env python3

# This file is part of Cockpit.
#
# Copyright (C) 2017 Red Hat, Inc.
#
# Cockpit is free software; you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation; either version 2.1 of the License, or
# (at your option) any later version.
#
# Cockpit is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with Cockpit; If not, see <http://www.gnu.org/licenses/>.

NAMES = [
    "example-task",
    "image-refresh",
    "naughty-prune",
]

# RHEL tasks have to be done inside Red Hat network
REDHAT_TASKS = [
    "rhel",
    "redhat"
]

import argparse
import pipes
import sys
import json
import logging

sys.dont_write_bytecode = True
logging.basicConfig(level=logging.INFO)

from lib import testmap
from task import github, distributed_queue, labels_of_pull

no_amqp = False
try:
    import pika
except ImportError:
    no_amqp = True


def main():
    parser = argparse.ArgumentParser(description="Scan issues for tasks")
    parser.add_argument("-v", "--human-readable", "--verbose", action="store_true", default=False,
                        dest="verbose", help="Print verbose information")
    parser.add_argument('--amqp', default=None,
                        help='The host:port of the AMQP server to publish to (format host:port)')
    parser.add_argument('--issues-data', default=None,
                        help='issues or pull request event GitHub JSON data to evaluate')
    parser.add_argument('--repo', default=None,
                        help='Repository to scan and checkout.')
    opts = parser.parse_args()

    if opts.amqp and no_amqp:
        parser.error("AMQP host:port specified but python-amqp not available")

    for result in scan(opts.issues_data, opts.verbose, opts.repo):
        if opts.amqp:
            with distributed_queue.DistributedQueue(opts.amqp, queues=['rhel', 'public']) as q:
                queue_task(q.channel, result)
            continue
        sys.stdout.write(result + "\n")

    return 0


def contains_any(string, matches):
    for match in matches:
        if match in string:
            return True
    return False

# Map all checkable work items to fixtures


def tasks_for_issues(issues_data, opts_repo):
    results = []
    issues = []

    if issues_data:
        event = json.loads(issues_data)
        repo = event["repository"]["full_name"]
        issue = event.get("issue") or event.get("pull_request")
        labels = labels_of_pull(issue)
        if 'bot' in labels:
            issues.append(issue)
        api = github.GitHub(repo=repo)
    else:
        api = github.GitHub(repo=opts_repo)
        issues = api.issues(state="open")

    for issue in issues:
        if issue["title"].strip().startswith("WIP"):
            continue
        login = issue.get("user", {}).get("login", {})
        if not api.is_user_allowed(login):
            continue

        #
        # We only consider the first unchecked item per issue
        #
        # The bots think the list needs to be done in order.
        # If the first item in the checklist is not something
        # the bots can do, then the bots will ignore this issue
        # (below in output_task)
        #
        checklist = github.Checklist(issue["body"])
        for item, checked in checklist.items.items():
            if not checked:
                results.append((item, issue, api.repo))
                break
    return results


def output_task(command, issue, repo, verbose):
    name, unused, context = command.partition(" ")
    if name not in NAMES:
        return None
    number = issue.get("number", None)
    if number is None:
        return None

    context = context.strip()
    checkout = "PRIORITY={priority:04d} "

    if repo == "cockpit-project/bots":
        # when working on bots run from project root
        cmd = "./{name} --verbose --issue='{issue}' {context}"
    else:
        # for external projects, nothing checks out bots/ subdir for them, so do it here
        cmd = "git clone .. bots && bots/{name} --verbose --issue='{issue}' {context}"

    # `--issues-data` should also be able to receive pull_request events, in that
    # case pull_request won't be present in the object, but commits will be
    if "pull_request" in issue or "commits" in issue:
        checkout += "./make-checkout --verbose --repo {repo} pull/{issue}/head && "
    else:
        checkout += "./make-checkout --verbose --repo {repo} {repo_default_branch} && "

    if verbose:
        return "issue-{issue} {name} {context}    {priority}".format(
            issue=int(number),
            priority=distributed_queue.MAX_PRIORITY,
            name=name,
            context=context
        )
    else:
        if context:
            context = pipes.quote(context)
        return (checkout + "cd make-checkout-workdir && " + cmd + " ; cd ..").format(
            issue=int(number),
            priority=distributed_queue.MAX_PRIORITY,
            name=name,
            context=context,
            repo=repo,
            repo_default_branch=testmap.get_default_branch(repo),
        )


def queue_task(channel, result):
    body = {
        "command": result,
        "type": "issue",
    }
    queue = 'rhel' if contains_any(result, REDHAT_TASKS) else 'public'
    channel.basic_publish('', queue, json.dumps(body),
                          properties=pika.BasicProperties(priority=distributed_queue.MAX_PRIORITY))
    logging.info("Published issue task with command: '{0}'".format(result))


# Default scan behavior run for each task
def scan(issues_data, verbose, opts_repo):
    global issues

    results = []

    # Now go through each fixture
    for (command, issue, repo) in tasks_for_issues(issues_data, opts_repo):
        result = output_task(command, issue, repo, verbose)
        if result is not None:
            results.append(result)

    return results


if __name__ == '__main__':
    sys.exit(main())
