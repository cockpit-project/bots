#!/usr/bin/env python3

# This file is part of Cockpit.
#
# Copyright (C) 2021 Red Hat, Inc.
#
# Cockpit is free software; you can redistribute it and/or modify it
# under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation; either version 2.1 of the License, or
# (at your option) any later version.
#
# Cockpit is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with Cockpit; If not, see <http://www.gnu.org/licenses/>.

import argparse
import logging
import sqlite3
import sys
import time
import urllib.parse

from lib import stores, s3


# Seconds in an hour
HOUR = 3600


def main():
    parser = argparse.ArgumentParser(description='Generate statistics about failed tests')
    parser.add_argument("--db", default="test-results.db", help="Database name")
    parser.add_argument("--hours", default=12, type=int,
                        help="Number of hours to take statistics from. Default is %(default)s.")
    parser.add_argument("--verbose", action="store_true", help="Enable verbose logging")
    opts = parser.parse_args()

    if opts.verbose:
        logging.basicConfig(level=logging.DEBUG)

    db_conn = sqlite3.connect(opts.db)
    cursor = db_conn.cursor()

    since = time.time() - opts.hours * HOUR

    # Output in prometheus format, see:
    # https://prometheus.io/docs/instrumenting/exposition_formats/
    output = ""

    # Get total number of runs and wait time sum in last N hours
    (test_runs, test_runs_queue_wait_sum) = cursor.execute("""\
            SELECT COUNT(*), SUM(wait_seconds)
            FROM TestRuns
            WHERE time > ? ;""", (since, )).fetchone()
    if test_runs_queue_wait_sum is None:
        test_runs_queue_wait_sum = 0

    # How many test runs waited for at most 5 minutes
    test_runs_wait_5m = cursor.execute("""\
            SELECT COUNT(*)
            FROM TestRuns
            WHERE time > ? AND wait_seconds <= 300; """, (since, )).fetchone()[0]

    # Get how many test runs waited for at most 1 hour
    test_runs_wait_1h = cursor.execute("""\
            SELECT COUNT(*)
            FROM TestRuns
            WHERE time > ? AND wait_seconds <= 3600; """, (since, )).fetchone()[0]

    output += f"""# HELP queue_time_wait_seconds histogram of queue wait times in the last {opts.hours} hours
# TYPE queue_time_wait_seconds histogram
queue_time_wait_seconds_bucket{{le="300"}} {test_runs_wait_5m}
queue_time_wait_seconds_bucket{{le="3600"}} {test_runs_wait_1h}
queue_time_wait_seconds_bucket{{le="+Inf"}} {test_runs}
queue_time_wait_seconds_sum {test_runs_queue_wait_sum}
queue_time_wait_seconds_count {test_runs}

"""

    # failures
    top_failures = cursor.execute("""
            SELECT TestRuns.project, t1.testname, (t2.failed * 100.0) / COUNT(run) AS percent
            FROM Tests AS t1
            JOIN TestRuns ON t1.run = TestRuns.id
            JOIN (
                SELECT testname, COUNT(run) as failed
                FROM Tests
                JOIN TestRuns ON Tests.run = TestRuns.id
                WHERE TestRuns.time > strftime('%s', 'now', '-7 days') AND Tests.failed = 1
                GROUP BY testname
            ) AS t2 ON t1.testname = t2.testname
            WHERE TestRuns.time > strftime('%s', 'now', '-7 days') AND t2.failed > 1
            GROUP BY t1.testname
            ORDER BY percent DESC
            LIMIT 50""").fetchall()

    output += """# HELP top_failures_pct Most unstable tests in the last 7 days (more than 10% failure rate)
# TYPE top_failures_pct gauge
"""
    for (project, test, fail_pct) in top_failures:
        if fail_pct > 10:
            output += f'top_failures_pct{{project="{project}",test="{test}"}} {fail_pct}\n'

    # PR retries in the last 24 hours
    pr_retries = cursor.execute("""
            SELECT project, revision, MAX(retry)
            FROM TestRuns
            WHERE time > strftime('%s', 'now', '-24 hours')
            GROUP BY project, revision""").fetchall()
    retry_buckets = {}
    for (project, revision, retries) in pr_retries:
        retry_buckets[retries] = retry_buckets.setdefault(retries, 0) + 1
    acc = 0

    output += """
# HELP pr_retries histogram of how many retries it took to get PRs from last 24h to green
# TYPE pr_retries histogram
"""
    for retry_count in sorted(retry_buckets):
        acc += retry_buckets[retry_count]
        output += f'pr_retries_bucket{{le="{retry_count}"}} {acc}\n'
    output += f'''pr_retries_bucket{{le="+Inf"}} {acc}
pr_retries_sum {acc}
pr_retries_count {acc}
'''

    # S3 space usage
    space_usage = {}
    for uri in stores.HYBRID_STORES:
        url = urllib.parse.urlparse(uri)

        if s3.is_key_present(url):
            space_usage[uri] = sum(int(size) for size, in s3.parse_list(s3.list_bucket(url), "Size"))
    if space_usage:
        output += """
# HELP s3_usage_bytes gauge of how much disk space an S3 store is using
# TYPE s3_usage_bytes gauge
"""
        for uri, size in space_usage.items():
            output += f's3_usage_bytes{{store="{uri}"}} = {size}\n'

    print(output)

    db_conn.close()


if __name__ == '__main__':
    sys.exit(main())
